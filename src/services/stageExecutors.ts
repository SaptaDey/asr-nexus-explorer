/**
 * ASR-GoT Stage Execution Functions
 * Implements all 9 stages of the ASR-GoT framework
 */

import { GraphData, GraphNode, GraphEdge, ResearchContext, APICredentials } from '@/types/asrGotTypes';
import { callGeminiAPI } from './apiService';

export interface StageExecutorContext {
  apiKeys: APICredentials;
  graphData: GraphData;
  researchContext: ResearchContext;
  stageResults: string[];
  setGraphData: (updater: (prev: GraphData) => GraphData) => void;
  setResearchContext: (updater: (prev: ResearchContext) => ResearchContext) => void;
  routeApiCall?: (prompt: string, additionalParams?: any) => Promise<any>;
}

export const initializeGraph = async (
  taskDescription: string,
  context: StageExecutorContext
): Promise<string> => {
  // Defensive checks
  if (!context) {
    throw new Error('StageExecutorContext is undefined');
  }
  if (!context.apiKeys) {
    throw new Error('API credentials are missing from context');
  }
  if (!context.apiKeys.gemini) {
    throw new Error('Gemini API key is missing. Please configure your API credentials first.');
  }
  
  // RULE 5 COMPLIANCE: Stage 1 Initialization = THINKING + STRUCTURED_OUTPUTS
  const analysisPrompt = `You are a PhD-level researcher. Perform a comprehensive analysis of this research question:

Research Question: "${taskDescription}"

Please provide a structured analysis with:
1. **Field Analysis**: Identify the primary scientific field, key research objectives, and potential interdisciplinary connections
2. **Current Background**: Analyze recent scientific developments, publications, and trends in this field
3. **Key Researchers**: Identify leading researchers and institutions working in this area
4. **Methodological Approaches**: Common research methodologies used in this field
5. **Recent Breakthroughs**: Latest significant findings or innovations (within last 2 years)

Provide a comprehensive foundation for research planning.`;

  const comprehensiveAnalysis = context.routeApiCall 
    ? await context.routeApiCall(analysisPrompt, { 
        stageId: '1', 
        graphHash: JSON.stringify(context.graphData).slice(0, 100) 
      })
    : await callGeminiAPI(
        analysisPrompt,
        context.apiKeys.gemini,
        'thinking-structured', // RULE 5: Stage 1 = THINKING + STRUCTURED_OUTPUTS
        undefined,
        { 
          stageId: '1', 
          graphHash: JSON.stringify(context.graphData).slice(0, 100) 
        }
      );

  const rootNode: GraphNode = {
    id: '1.0',
    label: 'Task Understanding',
    type: 'root',
    confidence: [0.8, 0.8, 0.8, 0.8],
    metadata: {
      parameter_id: 'P1.1',
      type: 'Root',
      source_description: 'Initial task understanding with AI analysis',
      value: taskDescription,
      timestamp: new Date().toISOString(),
      notes: comprehensiveAnalysis
    },
    position: { x: 400, y: 200 }
  };

  if (context.setGraphData) {
    context.setGraphData(prev => ({
    ...prev,
    nodes: [rootNode],
    edges: [],
    metadata: {
      ...prev.metadata,
      last_updated: new Date().toISOString(),
      total_nodes: 1,
      total_edges: 0,
      stage: 1
    }
    }));
  }

  // Update research context - extract field from comprehensive analysis
  const fieldMatch = comprehensiveAnalysis.match(/\*\*Field Analysis\*\*[\s\S]*?(\w+[\w\s]+)/);
  const field = fieldMatch ? fieldMatch[1].trim() : 'General Science';
  
  const newContext = {
    ...context.researchContext,
    field: field,
    topic: taskDescription,
    objectives: comprehensiveAnalysis.split('\n').filter(line => line.includes('objective')).slice(0, 3)
  };
  if (context.setResearchContext) {
    context.setResearchContext(() => newContext);
  }

  return `**Stage 1 Complete: Initialization**\n\n${comprehensiveAnalysis}`;
};

export const decomposeTask = async (
  dimensions: string[] | undefined,
  context: StageExecutorContext
): Promise<string> => {
  const defaultDimensions = ['Scope', 'Objectives', 'Constraints', 'Data Needs', 'Use Cases', 'Potential Biases', 'Knowledge Gaps'];
  const useDimensions = dimensions || defaultDimensions;

  // **BATCH API IMPLEMENTATION**: Process each dimension individually for proper branching
  const dimensionBatchPrompts = useDimensions.map((dimension, i) => 
    `You are a PhD-level researcher conducting Stage 2: Task Decomposition.

RESEARCH TOPIC: "${context.researchContext.topic}"

SPECIFIC DIMENSION TO ANALYZE: "${dimension}"

Analyze this dimension in detail for the research topic:

1. **Dimension-Specific Analysis**: Provide detailed insights specifically for "${dimension}" in the context of "${context.researchContext.topic}"
2. **Research Implications**: How does this dimension impact the research approach?
3. **Key Considerations**: What are the critical factors within this dimension?
4. **Methodological Requirements**: What methods are needed to address this dimension?
5. **Potential Challenges**: What difficulties might arise in this dimension?
6. **Success Criteria**: How will success in this dimension be measured?

Focus ONLY on the "${dimension}" dimension for the research topic: "${context.researchContext.topic}"

BATCH_INDEX: ${i}
DIMENSION_ID: 2.${i + 1}`
  );

  // Execute batch API call for all dimension analysis
  const batchDimensionResults = context.routeApiCall 
    ? await context.routeApiCall(dimensionBatchPrompts, { 
        batch: true,
        stageId: '2_decomposition_batch', 
        graphHash: JSON.stringify(context.graphData).slice(0, 100) 
      })
    : await Promise.all(dimensionBatchPrompts.map(prompt => 
        callGeminiAPI(prompt, context.apiKeys.gemini, 'thinking-structured')
      ));

  // Process batch results and create dimension nodes
  const dimensionNodes: GraphNode[] = useDimensions.map((dim, index) => {
    const dimensionAnalysis = Array.isArray(batchDimensionResults) 
      ? batchDimensionResults[index] 
      : batchDimensionResults;

    return {
      id: `2.${index + 1}`,
      label: dim,
      type: 'dimension' as const,
      confidence: [0.8, 0.8, 0.8, 0.8],
      metadata: {
        parameter_id: 'P1.2',
        type: 'Dimension',
        source_description: `AI-analyzed dimension: ${dim}`,
        value: dimensionAnalysis,
        timestamp: new Date().toISOString(),
        notes: dimensionAnalysis,
        dimension_focus: dim
      },
      position: { x: 200 + index * 150, y: 350 }
    };
  });

  const dimensionEdges: GraphEdge[] = dimensionNodes.map(node => ({
    id: `edge-1.0-${node.id}`,
    source: '1.0',
    target: node.id,
    type: 'supportive' as const,
    confidence: 0.8,
    metadata: {
      type: 'decomposition'
    }
  }));

  if (context.setGraphData) {
    context.setGraphData(prev => ({
    ...prev,
    nodes: [...prev.nodes, ...dimensionNodes],
    edges: [...prev.edges, ...dimensionEdges],
    metadata: {
      ...prev.metadata,
      last_updated: new Date().toISOString(),
      total_nodes: prev.nodes.length + dimensionNodes.length,
      total_edges: prev.edges.length + dimensionEdges.length,
      stage: 2
    }
    }));
  }

  // Create comprehensive results from batch analysis
  const dimensionResults = useDimensions.map((dim, index) => {
    const analysis = Array.isArray(batchDimensionResults) 
      ? batchDimensionResults[index] 
      : batchDimensionResults;
    return `**${dim} Analysis:**\n${analysis}\n`;
  });

  return `**Stage 2 Complete: Batch Decomposition Analysis**\n\n**Dimension-by-Dimension Analysis:**\n${dimensionResults.join('\n')}`;
};

export const generateHypotheses = async (
  customHypotheses: string[] | undefined,
  context: StageExecutorContext
): Promise<string> => {
  // Get all dimension nodes from Stage 2 to process individually
  const dimensionNodes = context.graphData.nodes.filter(node => node.type === 'dimension');
  
  if (dimensionNodes.length === 0) {
    throw new Error('No dimension nodes found from Stage 2. Cannot generate hypotheses.');
  }

  const allHypothesisNodes: GraphNode[] = [];
  const allHypothesisEdges: GraphEdge[] = [];
  const dimensionResults: string[] = [];

  // Process each dimension branch individually (PROPER GRAPH OF THOUGHTS)
  for (let i = 0; i < dimensionNodes.length; i++) {
    const dimension = dimensionNodes[i];
    
    // Generate hypotheses specifically for this dimension
    const dimensionHypothesisAnalysis = await (context.routeApiCall || callGeminiAPI)(
      `You are a PhD-level researcher conducting Stage 3: Hypothesis Generation.

RESEARCH TOPIC: "${context.researchContext.topic}"

SPECIFIC DIMENSION TO ANALYZE: "${dimension.label}"
DIMENSION DETAILS: ${dimension.metadata?.value || dimension.label}

Generate 2-3 SPECIFIC, TESTABLE hypotheses that directly address this dimension:

1. **Dimension-Specific Hypotheses**: Create hypotheses that specifically test aspects related to "${dimension.label}"
2. **Falsification Criteria**: Define clear, measurable criteria for each hypothesis
3. **Research Methods**: Suggest specific methods to test each hypothesis
4. **Expected Outcomes**: Predict measurable outcomes that would support/refute each hypothesis

Focus ONLY on hypotheses relevant to the "${dimension.label}" dimension. Each hypothesis must be:
- Testable with specific methodologies
- Directly related to the dimension being analyzed
- Measurable with clear success/failure criteria`,
      context.apiKeys.gemini,
      'thinking-structured',
      undefined,
      { 
        stageId: `3.${i + 1}`, 
        dimension: dimension.label,
        graphHash: JSON.stringify(context.graphData).slice(0, 100) 
      }
    );

    // Extract hypotheses specific to this dimension
    const dimensionHypotheses = dimensionHypothesisAnalysis.split('\n').filter(line => 
      line.includes('Hypothesis') || line.includes('H1:') || line.includes('H2:') || line.includes('H3:') || line.includes('**H')
    ).slice(0, 3); // 2-3 hypotheses per dimension

    // Create hypothesis nodes for this dimension
    const dimensionHypothesisNodes: GraphNode[] = dimensionHypotheses.map((hyp, hypIndex) => ({
      id: `3.${i + 1}.${hypIndex + 1}`,
      label: `${dimension.label} Hypothesis ${hypIndex + 1}`,
      type: 'hypothesis' as const,
      confidence: [0.7, 0.7, 0.7, 0.7],
      metadata: {
        parameter_id: 'P1.3',
        type: 'Hypothesis',
        source_description: `Hypothesis specific to ${dimension.label} dimension`,
        value: hyp,
        parent_dimension: dimension.id,
        timestamp: new Date().toISOString(),
        notes: dimensionHypothesisAnalysis,
        falsification_criteria: `Testable via experimental validation - ${hyp}`,
        impact_score: 0.7 + (hypIndex * 0.05)
      },
      position: { x: dimension.position.x + (hypIndex * 120), y: dimension.position.y + 200 }
    }));

    // Create edges from this dimension to its specific hypotheses
    const dimensionHypothesisEdges: GraphEdge[] = dimensionHypothesisNodes.map(hypNode => ({
      id: `edge-${dimension.id}-${hypNode.id}`,
      source: dimension.id,
      target: hypNode.id,
      type: 'supportive',
      confidence: 0.8,
      metadata: {
        type: 'dimension_hypothesis_derivation',
        parent_dimension: dimension.label
      }
    }));

    allHypothesisNodes.push(...dimensionHypothesisNodes);
    allHypothesisEdges.push(...dimensionHypothesisEdges);
    dimensionResults.push(`**${dimension.label} Analysis:**\n${dimensionHypothesisAnalysis}\n`);
  }

  if (context.setGraphData) {
    context.setGraphData(prev => ({
    ...prev,
    nodes: [...prev.nodes, ...allHypothesisNodes],
    edges: [...prev.edges, ...allHypothesisEdges],
    metadata: {
      ...prev.metadata,
      last_updated: new Date().toISOString(),
      total_nodes: prev.nodes.length + allHypothesisNodes.length,
      total_edges: prev.edges.length + allHypothesisEdges.length,
      stage: 3
    }
    }));
  }

  // Extract all hypotheses for research context
  const allHypothesesText = allHypothesisNodes.map(node => node.metadata?.value || node.label);

  if (context.setResearchContext) {
    context.setResearchContext(prev => ({
    ...prev,
    hypotheses: allHypothesesText
  }));
  }

  return `**Stage 3 Complete: Hypothesis Generation**\n\n**Branch-by-Branch Analysis:**\n${dimensionResults.join('\n')}`;
};

export const integrateEvidence = async (
  query: string | undefined,
  context: StageExecutorContext
): Promise<string> => {
  // Get all hypothesis nodes from Stage 3 to process individually
  const hypothesisNodes = context.graphData.nodes.filter(node => node.type === 'hypothesis');
  
  if (hypothesisNodes.length === 0) {
    throw new Error('No hypothesis nodes found from Stage 3. Cannot integrate evidence.');
  }

  const allEvidenceNodes: GraphNode[] = [];
  const allEvidenceEdges: GraphEdge[] = [];
  const hypothesisResults: string[] = [];

  // **BATCH API IMPLEMENTATION**: Process all hypotheses in optimized batches
  const hypothesisBatchPrompts = hypothesisNodes.map((hypothesis, i) => 
    `You are a PhD-level researcher conducting Stage 4: Evidence Integration.

RESEARCH TOPIC: "${context.researchContext.topic}"

SPECIFIC HYPOTHESIS TO ANALYZE: "${hypothesis.label}"
HYPOTHESIS DETAILS: ${hypothesis.metadata?.value || hypothesis.label}
PARENT DIMENSION: ${hypothesis.metadata?.parent_dimension || 'Unknown'}

Collect and analyze evidence SPECIFICALLY for this individual hypothesis:

1. **Targeted Evidence Search**: Find scientific evidence directly relevant to testing this specific hypothesis
2. **Study Identification**: Identify specific studies, papers, or data that could support/refute this hypothesis
3. **Quality Assessment**: Evaluate the methodological quality of evidence for this hypothesis
4. **Statistical Analysis**: Assess statistical power and significance of evidence related to this hypothesis
5. **Confidence Scoring**: Rate evidence strength from 0.0-1.0 for this specific hypothesis
6. **Research Gaps**: Identify missing evidence needed to properly test this hypothesis

Focus ONLY on evidence for this specific hypothesis: "${hypothesis.label}"
Do NOT analyze other hypotheses or general research topics.

BATCH_INDEX: ${i}
HYPOTHESIS_ID: ${hypothesis.id}`
  );

  // Execute batch API call for all hypotheses evidence collection
  const batchEvidenceResults = context.routeApiCall 
    ? await context.routeApiCall(hypothesisBatchPrompts, { 
        batch: true,
        stageId: '4_evidence_batch', 
        graphHash: JSON.stringify(context.graphData).slice(0, 100) 
      })
    : await Promise.all(hypothesisBatchPrompts.map(prompt => 
        callGeminiAPI(prompt, context.apiKeys.gemini, 'thinking-only')
      ));

  // Process batch results and create nodes/edges
  for (let i = 0; i < hypothesisNodes.length; i++) {
    const hypothesis = hypothesisNodes[i];
    const hypothesisEvidenceAnalysis = Array.isArray(batchEvidenceResults) 
      ? batchEvidenceResults[i] 
      : batchEvidenceResults;

    // Create evidence node specifically for this hypothesis
    const hypothesisEvidenceNode: GraphNode = {
      id: `4.${i + 1}`,
      label: `Evidence: ${hypothesis.label}`,
      type: 'evidence' as const,
      confidence: [0.8, 0.7, 0.8, 0.7],
      metadata: {
        parameter_id: 'P1.4',
        type: 'Evidence',
        source_description: `Evidence specific to hypothesis: ${hypothesis.label}`,
        value: hypothesisEvidenceAnalysis,
        parent_hypothesis: hypothesis.id,
        timestamp: new Date().toISOString(),
        notes: hypothesisEvidenceAnalysis,
        statistical_power: 0.75 + (i * 0.05)
      },
      position: { x: hypothesis.position.x, y: hypothesis.position.y + 200 }
    };

    // Create edge from hypothesis to its specific evidence
    const hypothesisEvidenceEdge: GraphEdge = {
      id: `edge-${hypothesis.id}-${hypothesisEvidenceNode.id}`,
      source: hypothesis.id,
      target: hypothesisEvidenceNode.id,
      type: 'supportive',
      confidence: 0.8,
      metadata: {
        type: 'hypothesis_evidence_link',
        parent_hypothesis: hypothesis.label
      }
    };

    allEvidenceNodes.push(hypothesisEvidenceNode);
    allEvidenceEdges.push(hypothesisEvidenceEdge);
    hypothesisResults.push(`**${hypothesis.label} Evidence:**\n${hypothesisEvidenceAnalysis}\n`);
  }

  if (context.setGraphData) {
    context.setGraphData(prev => ({
    ...prev,
    nodes: [...prev.nodes, ...allEvidenceNodes],
    edges: [...prev.edges, ...allEvidenceEdges],
    metadata: {
      ...prev.metadata,
      last_updated: new Date().toISOString(),
      total_nodes: prev.nodes.length + allEvidenceNodes.length,
      total_edges: prev.edges.length + allEvidenceEdges.length,
      stage: 4
    }
    }));
  }

  return `**Stage 4 Complete: Evidence Integration**\n\n**Branch-by-Branch Evidence Analysis:**\n${hypothesisResults.join('\n')}`;
};

export const pruneMergeNodes = async (context: StageExecutorContext): Promise<string> => {
  // Get all evidence nodes from Stage 4 to process individually
  const evidenceNodes = context.graphData.nodes.filter(node => node.type === 'evidence');
  
  if (evidenceNodes.length === 0) {
    throw new Error('No evidence nodes found from Stage 4. Cannot perform pruning/merging.');
  }

  const allPruningResults: string[] = [];
  const nodeQualityAssessments: any[] = [];

  // **BATCH API IMPLEMENTATION**: Process all evidence branches for pruning/merging
  const evidencePruningPrompts = evidenceNodes.map((evidence, i) => {
    // Get the parent hypothesis for this evidence
    const parentHypothesisEdge = context.graphData.edges.find(edge => edge.target === evidence.id);
    const parentHypothesis = parentHypothesisEdge 
      ? context.graphData.nodes.find(node => node.id === parentHypothesisEdge.source)
      : null;

    return `You are a PhD-level researcher conducting Stage 5: Pruning/Merging Analysis.

RESEARCH TOPIC: "${context.researchContext.topic}"

SPECIFIC EVIDENCE BRANCH TO ANALYZE: "${evidence.label}"
EVIDENCE DETAILS: ${evidence.metadata?.value || evidence.label}
PARENT HYPOTHESIS: ${parentHypothesis?.label || 'Unknown'}
EVIDENCE QUALITY: ${evidence.metadata?.statistical_power || 'Not specified'}

Analyze this specific evidence branch for pruning/merging decisions:

1. **Evidence Quality Assessment**: Rate the methodological quality of this specific evidence (0.0-1.0)
2. **Confidence Update**: Based on evidence strength, recommend updated confidence scores
3. **Pruning Decision**: Should this evidence branch be kept, merged, or removed?
4. **Merging Opportunities**: Identify other evidence that could be merged with this branch
5. **Connection Strength**: Assess the strength of this evidence's connection to its hypothesis
6. **Research Value**: How much does this evidence contribute to understanding the research topic?

Focus ONLY on this specific evidence branch: "${evidence.label}"
Provide specific recommendations for this evidence node and its connections.

BATCH_INDEX: ${i}
EVIDENCE_ID: ${evidence.id}`
  });

  // Execute batch API call for all evidence pruning analysis
  const batchPruningResults = context.routeApiCall 
    ? await context.routeApiCall(evidencePruningPrompts, { 
        batch: true,
        stageId: '5_pruning_batch', 
        graphHash: JSON.stringify(context.graphData).slice(0, 100) 
      })
    : await Promise.all(evidencePruningPrompts.map(prompt => 
        callGeminiAPI(prompt, context.apiKeys.gemini, 'thinking-only')
      ));

  // Process batch results and make pruning decisions
  const currentNodes = context.graphData.nodes;
  const currentEdges = context.graphData.edges;
  let prunedNodes = [...currentNodes];
  let prunedEdges = [...currentEdges];

  for (let i = 0; i < evidenceNodes.length; i++) {
    const evidence = evidenceNodes[i];
    const pruningAnalysis = Array.isArray(batchPruningResults) 
      ? batchPruningResults[i] 
      : batchPruningResults;
    
    allPruningResults.push(`**${evidence.label} Pruning Analysis:**\n${pruningAnalysis}\n`);

    // Extract quality score from analysis (simple pattern matching)
    const qualityMatch = pruningAnalysis.match(/quality.*?(\d\.\d+)/i);
    const qualityScore = qualityMatch ? parseFloat(qualityMatch[1]) : 0.5;
    
    // Extract pruning decision
    const shouldKeep = !pruningAnalysis.toLowerCase().includes('remove') && 
                      !pruningAnalysis.toLowerCase().includes('delete') &&
                      qualityScore >= 0.3;

    if (!shouldKeep) {
      // Remove this evidence node and its edges
      prunedNodes = prunedNodes.filter(node => node.id !== evidence.id);
      prunedEdges = prunedEdges.filter(edge => edge.source !== evidence.id && edge.target !== evidence.id);
    } else {
      // Update confidence based on quality assessment
      const nodeIndex = prunedNodes.findIndex(node => node.id === evidence.id);
      if (nodeIndex >= 0) {
        prunedNodes[nodeIndex] = {
          ...prunedNodes[nodeIndex],
          confidence: [qualityScore, qualityScore, qualityScore, qualityScore]
        };
      }
    }

    nodeQualityAssessments.push({
      nodeId: evidence.id,
      label: evidence.label,
      qualityScore,
      kept: shouldKeep,
      analysis: pruningAnalysis
    });
  }

  // Update graph with pruned data from batch analysis
  if (context.setGraphData) {
    context.setGraphData(prev => ({
    ...prev,
    nodes: prunedNodes,
    edges: prunedEdges,
    metadata: {
      ...prev.metadata,
      stage: 5,
      last_updated: new Date().toISOString(),
      total_nodes: prunedNodes.length,
      total_edges: prunedEdges.length,
      pruning_summary: nodeQualityAssessments
    }
    }));
  }

  const nodesRemoved = currentNodes.length - prunedNodes.length;
  const edgesRemoved = currentEdges.length - prunedEdges.length;
  const nodesKept = nodeQualityAssessments.filter(n => n.kept).length;

  return `**Stage 5 Complete: Branch-by-Branch Pruning/Merging for "${context.researchContext.topic}"**

**Optimization Results:**
- Evidence branches analyzed: ${evidenceNodes.length}
- Evidence branches kept: ${nodesKept}
- Evidence branches pruned: ${evidenceNodes.length - nodesKept}
- Total nodes: ${currentNodes.length} → ${prunedNodes.length} (${nodesRemoved} removed)
- Total edges: ${currentEdges.length} → ${prunedEdges.length} (${edgesRemoved} removed)

**Branch-by-Branch Quality Analysis:**
${allPruningResults.join('\n')}

**Quality Summary:**
${nodeQualityAssessments.map(assessment => 
  `- ${assessment.label}: Quality ${assessment.qualityScore.toFixed(2)} (${assessment.kept ? 'KEPT' : 'PRUNED'})`
).join('\n')}

**Next**: Ready for Stage 6 - Subgraph Extraction focused on "${context.researchContext.topic}"`;
};

export const extractSubgraphs = async (context: StageExecutorContext): Promise<string> => {
  // Get high-quality evidence nodes from Stage 5 to extract subgraphs from
  const evidenceNodes = context.graphData.nodes.filter(node => 
    node.type === 'evidence' && 
    node.confidence && 
    Array.isArray(node.confidence) && 
    (node.confidence.reduce((a, b) => a + b, 0) / node.confidence.length) >= 0.5
  );
  
  if (evidenceNodes.length === 0) {
    throw new Error('No high-quality evidence nodes found from Stage 5. Cannot extract subgraphs.');
  }

  const allSubgraphResults: string[] = [];
  const subgraphAssessments: any[] = [];

  // **BATCH API IMPLEMENTATION**: Analyze subgraph potential for each evidence cluster
  const subgraphBatchPrompts = evidenceNodes.map((evidence, i) => {
    // Get connected nodes for this evidence (hypothesis parent, related evidence)
    const parentHypothesisEdge = context.graphData.edges.find(edge => edge.target === evidence.id);
    const parentHypothesis = parentHypothesisEdge 
      ? context.graphData.nodes.find(node => node.id === parentHypothesisEdge.source)
      : null;
    
    // Get dimension grandparent
    const grandparentDimensionEdge = parentHypothesis 
      ? context.graphData.edges.find(edge => edge.target === parentHypothesis.id)
      : null;
    const grandparentDimension = grandparentDimensionEdge 
      ? context.graphData.nodes.find(node => node.id === grandparentDimensionEdge.source)
      : null;

    return `You are a PhD-level researcher conducting Stage 6: Subgraph Extraction.

RESEARCH TOPIC: "${context.researchContext.topic}"

EVIDENCE CLUSTER TO ANALYZE: "${evidence.label}"
EVIDENCE DETAILS: ${evidence.metadata?.value || evidence.label}
PARENT HYPOTHESIS: ${parentHypothesis?.label || 'Unknown'}
PARENT DIMENSION: ${grandparentDimension?.label || 'Unknown'}
EVIDENCE CONFIDENCE: ${evidence.confidence ? (evidence.confidence.reduce((a, b) => a + b, 0) / evidence.confidence.length).toFixed(2) : 'Unknown'}

Analyze this evidence cluster for subgraph extraction:

1. **Cluster Importance**: Rate the importance of this evidence cluster for understanding the research topic (0.0-1.0)
2. **Knowledge Pathway**: Identify the key reasoning pathway: Dimension → Hypothesis → Evidence
3. **Research Impact**: How critical is this cluster for answering the research question?
4. **Connection Strength**: Assess how well this evidence connects to other parts of the graph
5. **Insight Potential**: What key insights does this cluster provide?
6. **Composition Value**: How should this cluster be prioritized in the final composition?

Focus ONLY on this specific evidence cluster: "${evidence.label}"
Analyze its subgraph potential and research contribution.

BATCH_INDEX: ${i}
EVIDENCE_ID: ${evidence.id}`
  });

  // Execute batch API call for all subgraph analysis
  const batchSubgraphResults = context.routeApiCall 
    ? await context.routeApiCall(subgraphBatchPrompts, { 
        batch: true,
        stageId: '6_subgraph_batch', 
        graphHash: JSON.stringify(context.graphData).slice(0, 100) 
      })
    : await Promise.all(subgraphBatchPrompts.map(prompt => 
        callGeminiAPI(prompt, context.apiKeys.gemini, 'thinking-only')
      ));

  // Process batch results and rank subgraphs
  for (let i = 0; i < evidenceNodes.length; i++) {
    const evidence = evidenceNodes[i];
    const subgraphAnalysis = Array.isArray(batchSubgraphResults) 
      ? batchSubgraphResults[i] 
      : batchSubgraphResults;
    
    allSubgraphResults.push(`**${evidence.label} Subgraph Analysis:**\n${subgraphAnalysis}\n`);

    // Extract importance score from analysis
    const importanceMatch = subgraphAnalysis.match(/importance.*?(\d\.\d+)/i);
    const importanceScore = importanceMatch ? parseFloat(importanceMatch[1]) : 0.5;
    
    // Extract impact assessment
    const isHighImpact = subgraphAnalysis.toLowerCase().includes('critical') || 
                        subgraphAnalysis.toLowerCase().includes('essential') ||
                        importanceScore >= 0.7;

    subgraphAssessments.push({
      evidenceId: evidence.id,
      label: evidence.label,
      importanceScore,
      isHighImpact,
      analysis: subgraphAnalysis,
      parentHypothesis: context.graphData.edges.find(edge => edge.target === evidence.id)?.source || 'none'
    });
  }

  // Sort subgraphs by importance
  subgraphAssessments.sort((a, b) => b.importanceScore - a.importanceScore);
  
  const highImpactClusters = subgraphAssessments.filter(s => s.isHighImpact);
  const totalClusters = subgraphAssessments.length;

  return `**Stage 6 Complete: Batch Subgraph Extraction for "${context.researchContext.topic}"**

**Subgraph Analysis Results:**
- Evidence clusters analyzed: ${totalClusters}
- High-impact clusters identified: ${highImpactClusters.length}
- Top-ranked cluster: ${subgraphAssessments[0]?.label || 'None'} (Score: ${subgraphAssessments[0]?.importanceScore.toFixed(2) || 'N/A'})

**Cluster-by-Cluster Analysis:**
${allSubgraphResults.join('\n')}

**Importance Ranking:**
${subgraphAssessments.map((assessment, index) => 
  `${index + 1}. ${assessment.label}: Importance ${assessment.importanceScore.toFixed(2)} (${assessment.isHighImpact ? 'HIGH IMPACT' : 'Standard'})`
).join('\n')}

**Ready for Stage 7**: Composition will prioritize these ranked subgraphs for comprehensive analysis of "${context.researchContext.topic}"`;
};

export const composeResults = async (context: StageExecutorContext): Promise<string> => {
  // Get high-priority subgraphs from Stage 6 to compose sections for
  const stage6Results = context.stageResults.length >= 6 ? context.stageResults[5] : '';
  
  // Define composition sections for batch processing
  const compositionSections = [
    'Executive Summary',
    'Research Methodology', 
    'Key Findings',
    'Evidence Analysis',
    'Discussion & Implications',
    'Conclusions & Future Work'
  ];

  const allCompositionResults: string[] = [];
  const sectionAssessments: any[] = [];

  // Generate comprehensive statistics for context
  const nodeTypes = context.graphData.nodes.reduce((acc, node) => {
    acc[node.type] = (acc[node.type] || 0) + 1;
    return acc;
  }, {} as Record<string, number>);

  const averageConfidence = context.graphData.nodes
    .filter(n => n.confidence && n.confidence.length > 0)
    .map(n => n.confidence.reduce((a, b) => a + b, 0) / n.confidence.length)
    .reduce((sum, conf) => sum + conf, 0) / Math.max(1, context.graphData.nodes.length);

  // **BATCH API IMPLEMENTATION**: Process each composition section individually
  const compositionBatchPrompts = compositionSections.map((section, i) => {
    const relevantStageResults = context.stageResults.slice(0, 6).join('\n--- STAGE BREAK ---\n');
    
    return `You are a PhD-level researcher conducting Stage 7: Composition.

RESEARCH TOPIC: "${context.researchContext.topic}"

SPECIFIC SECTION TO COMPOSE: "${section}"

RESEARCH CONTEXT:
- Field: ${context.researchContext.field}
- Total Knowledge Nodes: ${context.graphData.nodes.length}
- Average Confidence: ${averageConfidence.toFixed(3)}
- Hypotheses Generated: ${context.researchContext.hypotheses.length}

STAGE 6 SUBGRAPH ANALYSIS:
${stage6Results}

RELEVANT RESEARCH PROGRESSION:
${relevantStageResults}

Compose the "${section}" section of the scientific report:

1. **Section-Specific Content**: Create comprehensive content specifically for "${section}"
2. **Research Integration**: Integrate findings from all previous stages relevant to this section
3. **Academic Quality**: Maintain PhD-level academic rigor and scientific methodology
4. **Evidence Citations**: Reference specific evidence and hypotheses where applicable
5. **Professional Formatting**: Use proper academic structure and formatting
6. **Research Coherence**: Ensure alignment with overall research objectives

Focus ONLY on the "${section}" section content.
Provide complete, publication-ready content for this specific section.

BATCH_INDEX: ${i}
SECTION_ID: ${section.toLowerCase().replace(/ /g, '_')}`
  });

  // Execute batch API call for all composition sections
  const batchCompositionResults = context.routeApiCall 
    ? await context.routeApiCall(compositionBatchPrompts, { 
        batch: true,
        stageId: '7_composition_batch', 
        graphHash: JSON.stringify(context.graphData).slice(0, 100) 
      })
    : await Promise.all(compositionBatchPrompts.map(prompt => 
        callGeminiAPI(prompt, context.apiKeys.gemini, 'thinking-structured')
      ));

  // Process batch results and compile sections
  for (let i = 0; i < compositionSections.length; i++) {
    const section = compositionSections[i];
    const sectionContent = Array.isArray(batchCompositionResults) 
      ? batchCompositionResults[i] 
      : batchCompositionResults;
    
    allCompositionResults.push(`## ${section}\n\n${sectionContent}\n`);

    sectionAssessments.push({
      sectionName: section,
      contentLength: sectionContent.length,
      hasEvidence: sectionContent.toLowerCase().includes('evidence'),
      hasHypotheses: sectionContent.toLowerCase().includes('hypothesis'),
      content: sectionContent
    });
  }

  // Compile final HTML document
  const finalHtmlReport = `<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Scientific Research Analysis: ${context.researchContext.topic}</title>
    <style>
        body { font-family: 'Times New Roman', serif; line-height: 1.6; max-width: 1200px; margin: 0 auto; padding: 20px; }
        h1 { color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px; }
        h2 { color: #34495e; border-bottom: 1px solid #bdc3c7; padding-bottom: 5px; margin-top: 30px; }
        .metadata { background: #f8f9fa; padding: 15px; border-left: 4px solid #3498db; margin: 20px 0; }
        .stats { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin: 20px 0; }
        .stat-box { background: #ffffff; border: 1px solid #dee2e6; padding: 15px; border-radius: 5px; text-align: center; }
    </style>
</head>
<body>
    <h1>Scientific Research Analysis: ${context.researchContext.topic}</h1>
    
    <div class="metadata">
        <strong>Research Field:</strong> ${context.researchContext.field}<br>
        <strong>Analysis Date:</strong> ${new Date().toLocaleDateString()}<br>
        <strong>Framework:</strong> ASR-GoT (Automatic Scientific Research - Graph of Thoughts)
    </div>

    <div class="stats">
        <div class="stat-box"><h3>${context.graphData.nodes.length}</h3>Knowledge Nodes</div>
        <div class="stat-box"><h3>${context.graphData.edges.length}</h3>Connections</div>
        <div class="stat-box"><h3>${averageConfidence.toFixed(2)}</h3>Avg Confidence</div>
        <div class="stat-box"><h3>${context.researchContext.hypotheses.length}</h3>Hypotheses</div>
    </div>

    ${allCompositionResults.join('\n')}

    <hr>
    <p><em>Generated by ASR-GoT Framework • ${new Date().toISOString()}</em></p>
</body>
</html>`;

  return `**Stage 7 Complete: Batch Composition for "${context.researchContext.topic}"**

**Composition Results:**
- Sections composed: ${compositionSections.length}
- Total content length: ${allCompositionResults.join('').length} characters
- HTML report generated with embedded styling and statistics

**Section Analysis:**
${sectionAssessments.map((assessment, index) => 
  `${index + 1}. ${assessment.sectionName}: ${assessment.contentLength} chars (Evidence: ${assessment.hasEvidence ? 'YES' : 'NO'}, Hypotheses: ${assessment.hasHypotheses ? 'YES' : 'NO'})`
).join('\n')}

**Final HTML Report:**
${finalHtmlReport}

**Ready for Stage 8**: Reflection will audit each composition section for quality and coherence.`
};

export const performReflection = async (context: StageExecutorContext): Promise<string> => {
  // Define reflection aspects for batch processing
  const reflectionAspects = [
    'Stage Coherence & Flow',
    'Research Focus & Scope',
    'Methodological Rigor',
    'Evidence Quality Assessment',
    'Logical Consistency',
    'Bias Detection',
    'Completeness & Coverage'
  ];

  const allReflectionResults: string[] = [];
  const reflectionAssessments: any[] = [];

  // Get previous stage results for context
  const stage7Results = context.stageResults.length >= 7 ? context.stageResults[6] : '';
  const allPreviousStages = context.stageResults.slice(0, 7).join('\n--- STAGE BREAK ---\n');

  // **BATCH API IMPLEMENTATION**: Process each reflection aspect individually
  const reflectionBatchPrompts = reflectionAspects.map((aspect, i) => {
    return `You are a PhD-level researcher conducting Stage 8: Critical Reflection.

RESEARCH TOPIC: "${context.researchContext.topic}"

SPECIFIC REFLECTION ASPECT: "${aspect}"

STAGE 7 COMPOSITION RESULTS:
${stage7Results}

COMPLETE RESEARCH PROGRESSION:
${allPreviousStages}

RESEARCH CONTEXT:
${JSON.stringify(context.researchContext, null, 2)}

Perform critical audit specifically for "${aspect}":

1. **Specific Assessment**: Focus ONLY on "${aspect}" in the context of "${context.researchContext.topic}"
2. **Quality Evaluation**: Rate the quality of this aspect (0.0-1.0) with justification
3. **Strengths Identification**: What worked well in this aspect?
4. **Weaknesses Detection**: What issues or gaps exist in this aspect?
5. **Improvement Recommendations**: Specific recommendations for enhancing this aspect
6. **Risk Assessment**: What risks does this aspect pose to research validity?

Focus ONLY on the "${aspect}" aspect of the research analysis.
Provide specific, actionable feedback for this reflection area.

BATCH_INDEX: ${i}
ASPECT_ID: ${aspect.toLowerCase().replace(/ /g, '_')}`
  });

  // Execute batch API call for all reflection aspects
  const batchReflectionResults = context.routeApiCall 
    ? await context.routeApiCall(reflectionBatchPrompts, { 
        batch: true,
        stageId: '8_reflection_batch', 
        graphHash: JSON.stringify(context.graphData).slice(0, 100) 
      })
    : await Promise.all(reflectionBatchPrompts.map(prompt => 
        callGeminiAPI(prompt, context.apiKeys.gemini, 'thinking-only')
      ));

  // Process batch results and extract assessments
  for (let i = 0; i < reflectionAspects.length; i++) {
    const aspect = reflectionAspects[i];
    const reflectionAnalysis = Array.isArray(batchReflectionResults) 
      ? batchReflectionResults[i] 
      : batchReflectionResults;
    
    allReflectionResults.push(`### ${aspect}\n\n${reflectionAnalysis}\n`);

    // Extract quality score from analysis
    const qualityMatch = reflectionAnalysis.match(/quality.*?(\d\.\d+)/i);
    const qualityScore = qualityMatch ? parseFloat(qualityMatch[1]) : 0.7;
    
    // Extract key issues
    const hasIssues = reflectionAnalysis.toLowerCase().includes('weakness') || 
                     reflectionAnalysis.toLowerCase().includes('gap') ||
                     reflectionAnalysis.toLowerCase().includes('issue');

    reflectionAssessments.push({
      aspectName: aspect,
      qualityScore,
      hasIssues,
      analysisLength: reflectionAnalysis.length,
      analysis: reflectionAnalysis
    });
  }

  // Calculate overall reflection metrics
  const averageQuality = reflectionAssessments.reduce((sum, assessment) => sum + assessment.qualityScore, 0) / reflectionAssessments.length;
  const issueCount = reflectionAssessments.filter(assessment => assessment.hasIssues).length;
  const highQualityCount = reflectionAssessments.filter(assessment => assessment.qualityScore >= 0.8).length;

  return `**Stage 8 Complete: Batch Critical Reflection for "${context.researchContext.topic}"**

**Reflection Overview:**
- Aspects analyzed: ${reflectionAspects.length}
- Average quality score: ${averageQuality.toFixed(2)}
- Aspects with issues identified: ${issueCount}
- High-quality aspects (≥0.8): ${highQualityCount}

**Aspect-by-Aspect Analysis:**
${allReflectionResults.join('\n')}

**Quality Summary:**
${reflectionAssessments.map((assessment, index) => 
  `${index + 1}. ${assessment.aspectName}: Quality ${assessment.qualityScore.toFixed(2)} (${assessment.hasIssues ? 'ISSUES FOUND' : 'No Issues'})`
).join('\n')}

**Ready for Stage 9**: Final analysis will synthesize these reflection insights into comprehensive conclusions.`
};

export const generateFinalAnalysis = async (context: StageExecutorContext): Promise<string> => {
  // Define final analysis components for batch processing
  const analysisComponents = [
    'Executive Summary',
    'Key Findings & Discoveries',
    'Research Implications',
    'Future Research Directions',
    'Practical Applications',
    'Limitations & Caveats'
  ];

  const allFinalResults: string[] = [];
  const componentAssessments: any[] = [];

  // Get previous stage results for context
  const stage8Results = context.stageResults.length >= 8 ? context.stageResults[7] : '';
  const stage7Results = context.stageResults.length >= 7 ? context.stageResults[6] : '';
  const allPreviousStages = context.stageResults.slice(0, 8).join('\n--- STAGE BREAK ---\n');

  // Generate comprehensive statistics
  const nodeTypes = context.graphData.nodes.reduce((acc, node) => {
    acc[node.type] = (acc[node.type] || 0) + 1;
    return acc;
  }, {} as Record<string, number>);

  const averageConfidence = context.graphData.nodes
    .filter(n => n.confidence && n.confidence.length > 0)
    .map(n => n.confidence.reduce((a, b) => a + b, 0) / n.confidence.length)
    .reduce((sum, conf) => sum + conf, 0) / Math.max(1, context.graphData.nodes.length);

  // **BATCH API IMPLEMENTATION**: Process each final analysis component individually
  const finalAnalysisBatchPrompts = analysisComponents.map((component, i) => {
    return `You are a PhD-level researcher conducting Stage 9: Final Analysis.

RESEARCH TOPIC: "${context.researchContext.topic}"

SPECIFIC COMPONENT TO ANALYZE: "${component}"

STAGE 8 REFLECTION RESULTS:
${stage8Results}

STAGE 7 COMPOSITION RESULTS:
${stage7Results}

COMPLETE RESEARCH PROGRESSION:
${allPreviousStages}

RESEARCH STATISTICS:
- Total Knowledge Nodes: ${context.graphData.nodes.length}
- Average Confidence: ${averageConfidence.toFixed(3)}
- Node Types: ${JSON.stringify(nodeTypes)}
- Hypotheses Generated: ${context.researchContext.hypotheses.length}

Create comprehensive "${component}" for the final analysis:

1. **Component-Specific Content**: Focus exclusively on "${component}" aspects
2. **Research Integration**: Synthesize insights from all 8 previous stages
3. **Academic Rigor**: Maintain PhD-level analysis and conclusions
4. **Evidence-Based**: Ground all statements in the evidence collected
5. **Future-Oriented**: Consider implications and future directions where applicable
6. **Practical Value**: Emphasize actionable insights and applications

Focus ONLY on the "${component}" component of the final analysis.
Provide comprehensive, publication-ready content for this specific component.

BATCH_INDEX: ${i}
COMPONENT_ID: ${component.toLowerCase().replace(/ /g, '_')}`
  });

  // Execute batch API call for all final analysis components
  const batchFinalResults = context.routeApiCall 
    ? await context.routeApiCall(finalAnalysisBatchPrompts, { 
        batch: true,
        stageId: '9_final_analysis_batch', 
        graphHash: JSON.stringify(context.graphData).slice(0, 100) 
      })
    : await Promise.all(finalAnalysisBatchPrompts.map(prompt => 
        callGeminiAPI(prompt, context.apiKeys.gemini, 'thinking-structured')
      ));

  // Process batch results and compile final analysis
  for (let i = 0; i < analysisComponents.length; i++) {
    const component = analysisComponents[i];
    const componentContent = Array.isArray(batchFinalResults) 
      ? batchFinalResults[i] 
      : batchFinalResults;
    
    allFinalResults.push(`### ${component}\n\n${componentContent}\n`);

    componentAssessments.push({
      componentName: component,
      contentLength: componentContent.length,
      hasActionableInsights: componentContent.toLowerCase().includes('recommend') || componentContent.toLowerCase().includes('suggest'),
      hasEvidence: componentContent.toLowerCase().includes('evidence') || componentContent.toLowerCase().includes('data'),
      content: componentContent
    });
  }

  // Calculate final analysis metrics
  const actionableCount = componentAssessments.filter(comp => comp.hasActionableInsights).length;
  const evidenceBasedCount = componentAssessments.filter(comp => comp.hasEvidence).length;
  const totalContentLength = allFinalResults.join('').length;

  return `# **STAGE 9 COMPLETE: Comprehensive Final Analysis for "${context.researchContext.topic}"**

## **ASR-GoT Framework Analysis Complete - 9/9 Stages Executed**

**Final Analysis Overview:**
- Components analyzed: ${analysisComponents.length}
- Total content generated: ${totalContentLength} characters
- Components with actionable insights: ${actionableCount}
- Evidence-based components: ${evidenceBasedCount}
- Research nodes processed: ${context.graphData.nodes.length}
- Average confidence: ${averageConfidence.toFixed(3)}

---

## **COMPREHENSIVE FINAL ANALYSIS**

${allFinalResults.join('\n')}

---

## **Component Quality Assessment:**
${componentAssessments.map((assessment, index) => 
  `**${index + 1}. ${assessment.componentName}:**
- Content Length: ${assessment.contentLength} characters
- Actionable Insights: ${assessment.hasActionableInsights ? '✓' : '✗'}
- Evidence-Based: ${assessment.hasEvidence ? '✓' : '✗'}`
).join('\n\n')}

---

## **ASR-GoT Framework Summary:**

**Research Topic:** ${context.researchContext.topic}
**Research Field:** ${context.researchContext.field}
**Analysis Date:** ${new Date().toLocaleDateString()}
**Framework Version:** ASR-GoT (Automatic Scientific Research - Graph of Thoughts)

**Complete 9-Stage Pipeline Executed:**
✓ Stage 1: Initialization & Root Node Creation
✓ Stage 2: Multi-Dimensional Decomposition (Batch Processed)
✓ Stage 3: Hypothesis Generation per Dimension (Batch Processed) 
✓ Stage 4: Evidence Integration per Hypothesis (Batch Processed)
✓ Stage 5: Pruning/Merging per Evidence Branch (Batch Processed)
✓ Stage 6: Subgraph Extraction per Evidence Cluster (Batch Processed)
✓ Stage 7: Composition per Report Section (Batch Processed)
✓ Stage 8: Critical Reflection per Aspect (Batch Processed)
✓ Stage 9: Final Analysis per Component (Batch Processed)

**Graph Statistics:**
- Knowledge Nodes: ${context.graphData.nodes.length}
- Connections: ${context.graphData.edges.length}
- Node Types: ${JSON.stringify(nodeTypes)}
- Hypotheses Generated: ${context.researchContext.hypotheses.length}

**🎉 RESEARCH ANALYSIS COMPLETE 🎉**

This comprehensive analysis represents a complete PhD-level scientific investigation using the ASR-GoT framework with optimal batch API processing for maximum efficiency and branch coherency.`

};
